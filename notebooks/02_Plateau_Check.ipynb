{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc85630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ro_f64(a):\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    a.setflags(write=False)\n",
    "    return a\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class IngestData:\n",
    "    \"\"\"Arrays extracted from Parquet.\"\"\"\n",
    "\n",
    "    time_ps: np.ndarray\n",
    "    mean: np.ndarray\n",
    "    stdev: np.ndarray\n",
    "    n_rows: int\n",
    "\n",
    "    @classmethod\n",
    "    def make(cls, time_ps, mean, stdev):\n",
    "        \"\"\" \"Normalize data types\"\"\"\n",
    "        tp = _ro_f64(time_ps)\n",
    "        m = _ro_f64(mean)\n",
    "        sd = _ro_f64(stdev)\n",
    "        if not (len(tp) == len(m) == len(sd)):\n",
    "            raise ValueError(\"Column lengths differ.\")\n",
    "        return cls(tp, m, sd, len(tp))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MaskInfo:\n",
    "    \"\"\"Masks and index windows for eta and sigma fits.\"\"\"\n",
    "\n",
    "    tmin_ps: float\n",
    "    tmax_ps: float\n",
    "    i0_eta: int\n",
    "    i1_eta: int\n",
    "    i1_sigma: int\n",
    "    eta_mask: np.ndarray\n",
    "    sigma_mask: np.ndarray\n",
    "    n_eta: int\n",
    "    n_sigma: int\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class CutoffResult:\n",
    "    chosen_index: float\n",
    "    chosen_time_ps: float\n",
    "    pass_streak: int\n",
    "    params: dict\n",
    "    candidate_times_ps: np.ndarray\n",
    "    mapped_indices: np.ndarray\n",
    "    pass_flags: np.ndarray\n",
    "    rel_range: np.ndarray\n",
    "    abs_range: np.ndarray\n",
    "    window_sizes_ps: np.ndarray\n",
    "    window_counts: np.ndarray\n",
    "    eta_median: np.ndarray\n",
    "    eta_mad: np.ndarray\n",
    "    table: str\n",
    "\n",
    "\n",
    "class RunLog:\n",
    "    \"\"\"Line-oriented logger.\"\"\"\n",
    "\n",
    "    def __init__(self, log_name=None, program=None):\n",
    "        default = \"ViscoFit.log\"\n",
    "        base = Path(log_name or default)\n",
    "        base.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.path = self._resolve_unique_path(base)\n",
    "        self.program = program or \"generic\"\n",
    "        self._lines = []\n",
    "        self._write_header()\n",
    "\n",
    "    def _resolve_unique_path(self, base):\n",
    "        stem, suffix = base.stem, base.suffix or \"\"\n",
    "        i = 0\n",
    "        while True:\n",
    "            candidate = base if i == 0 else base.with_name(f\"{stem}_{i + 1}{suffix}\")\n",
    "            try:\n",
    "                # Atomic create for safety\n",
    "                with open(candidate, \"x\", encoding=\"utf-8\") as fh:\n",
    "                    fh.write(\"\")\n",
    "                return candidate\n",
    "            except FileExistsError:\n",
    "                i += 1\n",
    "\n",
    "    def _stamp(self):\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    def _write_header(self):\n",
    "        \"\"\"Write header block at instantiation.\"\"\"\n",
    "        if self.program == \"generic\":\n",
    "            program_name = \"RheoKit\"\n",
    "        elif self.program == \"platchk\":\n",
    "            program_name = \"RheoKit: Plateau Check\"\n",
    "        elif self.program == \"cvfit\":\n",
    "            program_name = \"RheoKit: Stress Fit\"\n",
    "        elif self.program == \"runGK\":\n",
    "            program_name = \"RheoKit: GK Integrate\"\n",
    "\n",
    "        author_name = \"Daniel Relix\"\n",
    "        timestamp = self._stamp()\n",
    "\n",
    "        box_width = 64\n",
    "        left_margin = \" \" * 13\n",
    "        pad_inside = box_width - 4  # subtract 2 chars for each '##'\n",
    "        line = lambda text=\"\": f\"{left_margin}##  {text:<{pad_inside - 2}}##\"\n",
    "\n",
    "        header = [\n",
    "            \"\",\n",
    "            left_margin + \"#\" * box_width,\n",
    "            left_margin + \"##\" + \" \" * (box_width - 4) + \"##\",\n",
    "            line(program_name),\n",
    "            line(f\"By {author_name}\"),\n",
    "            left_margin + \"##\" + \" \" * (box_width - 4) + \"##\",\n",
    "            left_margin + \"#\" * box_width,\n",
    "            \"\",\n",
    "            f\"Job started: {timestamp}\",\n",
    "            f\"Log file: {self.path.name}\",\n",
    "            \"\",\n",
    "        ]\n",
    "\n",
    "        self._lines.extend(header)\n",
    "        self.write()\n",
    "\n",
    "    def add(self, line=\"\"):\n",
    "        self._lines.append(\"   \" + line)\n",
    "\n",
    "    def section(self, title):\n",
    "        self._lines.append(\"-\" * 90)\n",
    "        self._lines.append(title)\n",
    "\n",
    "    def subsection(self, title):\n",
    "        self._lines.append(title)\n",
    "\n",
    "    def write(self):\n",
    "        self.path.write_text(\"\\n\".join(self._lines) + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "    def exception(self, logtext, e):\n",
    "        self._lines.append(f\"Exception: {logtext}\")\n",
    "        tb = \"\".join(traceback.format_exception(type(e), e, e.__traceback__))\n",
    "        self._lines.append(tb.rstrip(\"\\n\"))\n",
    "        self.write()\n",
    "\n",
    "\n",
    "def _mad(x: np.ndarray) -> float:\n",
    "    m = float(np.nanmedian(x))\n",
    "    return float(np.nanmedian(np.abs(x - m)))\n",
    "\n",
    "\n",
    "def load_parquet(path, log=None):\n",
    "    \"\"\"\n",
    "    Load Parquet with required columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the Parquet file.\n",
    "    log : RunLog or None\n",
    "        Optional logger to record a brief ingest block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    IngestData\n",
    "        time_ps, mean, stdev as float64 arrays and row count.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If required columns are missing.\n",
    "    \"\"\"\n",
    "\n",
    "    required_cols = (\"Time (ps)\", \"Mean\", \"StDev\")\n",
    "    df = pd.read_parquet(path, columns=[\"Time (ps)\", \"Mean\", \"StDev\"])\n",
    "    data = IngestData.make(df[\"Time (ps)\"], df[\"Mean\"], df[\"StDev\"])\n",
    "\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    if log is not None:\n",
    "        log.section(\"INPUT DATA\")\n",
    "        log.add()\n",
    "\n",
    "        log.add(f\"File               : {path}\")\n",
    "        log.add(f\"Simulation Time    : {data.time_ps[-1]} ps\")\n",
    "        log.add(f\"Total Data Points  : {data.n_rows}\")\n",
    "        log.add()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_masks(time_ps, tmin_ps=2.0, tmax_ps=None, log=None, *, silent=False):\n",
    "    \"\"\"\n",
    "    Build eta and sigma windows/masks using times in ps.\n",
    "\n",
    "    Windows:\n",
    "      - eta   : [tmin_ps, tmax_ps]  (default tmin_ps=2.0)\n",
    "      - sigma : [0,       tmax_ps]  (shares the same cutoff)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_ps : np.ndarray\n",
    "        1D array of times (ps), length N.\n",
    "    tmin_ps : float\n",
    "        Start time (ps) for eta window. Default is 2.0 ps.\n",
    "    tmax_ps : float or None\n",
    "        End time (ps). If None, uses the last time in the array.\n",
    "    log : RunLog or None\n",
    "        Optional logger to record window details.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MaskInfo\n",
    "        Indices, masks, and counts for eta and sigma windows.\n",
    "    \"\"\"\n",
    "\n",
    "    tmin = float(tmin_ps)\n",
    "    tmax = float(time_ps[-1]) if tmax_ps is None else float(tmax_ps)\n",
    "\n",
    "    # Map times to indices (inclusive right end for eta/sigma)\n",
    "    i0_eta = int(np.searchsorted(time_ps, tmin, side=\"left\"))\n",
    "    i1_eta = int(np.searchsorted(time_ps, tmax, side=\"right\") - 1)\n",
    "    i1_eta = max(i1_eta, i0_eta)  # ensure non-empty ordering\n",
    "\n",
    "    # Sigma starts at 0 and ends at same cutoff as eta\n",
    "    i1_sigma = i1_eta\n",
    "\n",
    "    # Make the masks\n",
    "    N = time_ps.size\n",
    "    eta_mask = np.zeros(N, dtype=bool)\n",
    "    sigma_mask = np.zeros(N, dtype=bool)\n",
    "    eta_mask[i0_eta : i1_eta + 1] = True\n",
    "    sigma_mask[0 : i1_sigma + 1] = True\n",
    "\n",
    "    n_eta = int(eta_mask.sum())\n",
    "    n_sigma = int(sigma_mask.sum())\n",
    "\n",
    "    if not silent and log is not None:\n",
    "        log.section(\"MASKS\")\n",
    "        log.add()\n",
    "        log.add(f\"Sigma Fit Range    : {0.0:.6g} - {tmax:.6g} ps \")\n",
    "        log.add(f\"Index Range        : [0, {i1_sigma}]\")\n",
    "\n",
    "        log.add()\n",
    "        log.add(f\"Eta Fit Range      : {tmin:.6g} - {tmax:.6g} ps\")\n",
    "        log.add(f\"Index Range        : [{i0_eta}, {i1_eta}]\")\n",
    "        log.add(f\"Points in Eta Fit  : {n_eta}\")\n",
    "        log.add()\n",
    "\n",
    "    masks = MaskInfo(\n",
    "        tmin_ps=tmin,\n",
    "        tmax_ps=tmax,\n",
    "        i0_eta=i0_eta,\n",
    "        i1_eta=i1_eta,\n",
    "        i1_sigma=i1_sigma,\n",
    "        eta_mask=eta_mask,\n",
    "        sigma_mask=sigma_mask,\n",
    "        n_eta=n_eta,\n",
    "        n_sigma=n_sigma,\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "\n",
    "# Main Logic\n",
    "def cutoff_checker(\n",
    "    parquet_path,\n",
    "    *,\n",
    "    candidate_times_ps,\n",
    "    W_fraction=0.10,\n",
    "    eps_rel=0.02,\n",
    "    eps_abs=None,\n",
    "    pass_streak=2,\n",
    "    log_name=\"plateau_check.log\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Test the provided cutoff times to see if the median of the data is flat.\n",
    "\n",
    "    Candidate mapping: for a provided cutoff time tc, we use j = max { i : t[i] <= tc }.\n",
    "    A candidate is considered invalid if it does not map inside the eta_mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data & masks\n",
    "    log = RunLog(log_name=log_name, program=\"platchk\")\n",
    "    data = load_parquet(parquet_path, log=log)\n",
    "    t = np.asarray(data.time_ps, dtype=float)\n",
    "    eta = np.asarray(data.mean, dtype=float)\n",
    "    _sig = np.asarray(data.stdev, dtype=float)\n",
    "\n",
    "    masks = build_masks(t, tmin_ps=0.0, tmax_ps=None, log=log, silent=True)\n",
    "    eta_idx = np.where(masks.eta_mask)[0]\n",
    "    if eta_idx.size == 0:\n",
    "        msg = \"No eta candidates available.\"\n",
    "        e = RuntimeError(\"Empty Eta Mask\")\n",
    "        if log:\n",
    "            log.section(\"CUTOFF CHECKER â€“ RESULT\")\n",
    "            log.exception(msg, RuntimeError, e)\n",
    "        raise RuntimeError(msg)\n",
    "\n",
    "    t_eta0 = t[eta_idx[0]]\n",
    "\n",
    "    # Map candidate cutoff times to array idxs\n",
    "    user_times = np.asarray(candidate_times_ps, dtype=float)\n",
    "    mapped_idx = np.full(user_times.shape, -1, dtype=int)\n",
    "\n",
    "    for k, tc in enumerate(user_times):\n",
    "        j = int(np.searchsorted(t, tc, side=\"right\") - 1)\n",
    "        if 0 <= j < t.size and masks.eta_mask[j]:\n",
    "            mapped_idx[k] = j\n",
    "\n",
    "    # Log settings\n",
    "    if log:\n",
    "        log.section(\"PLATEAU WINDOW SETTINGS\")\n",
    "        log.add()\n",
    "        log.add(f\"Window fraction     : {W_fraction}\")\n",
    "        log.add(f\"eps relative        : {eps_rel}\")\n",
    "        log.add(\n",
    "            f\"eps absolute        : {eps_abs if eps_abs is not None else 'No Threshold Set'}\"\n",
    "        )\n",
    "        log.add(f\"Min. pass streak    : {pass_streak}\")\n",
    "        log.add()\n",
    "\n",
    "    # Evaluate medians for each plateau window\n",
    "    n = user_times.size\n",
    "    rel_range = np.full(n, np.nan, dtype=float)\n",
    "    abs_range = np.full(n, np.nan, dtype=float)\n",
    "    pass_flags = np.zeros(n, dtype=bool)\n",
    "    floor_used = np.zeros(n, dtype=bool)\n",
    "\n",
    "    W_used_ps = np.full(n, np.nan, dtype=float)\n",
    "    npts_win = np.full(n, 0, dtype=int)\n",
    "    eta_med = np.full(n, np.nan, dtype=float)\n",
    "    eta_mad = np.full(n, np.nan, dtype=float)\n",
    "\n",
    "    use_abs_check = eps_abs is not None\n",
    "\n",
    "    def _window_start_index(tj):\n",
    "        frac = float(W_fraction) * max(tj - t_eta0, 0.0)\n",
    "        # apply internal floor\n",
    "        Wj = frac if frac >= 0.5 else 0.5\n",
    "        floor = (Wj == 0.5) and (frac < 0.5)\n",
    "        left_t = tj - Wj\n",
    "        i0 = int(np.searchsorted(t, left_t, side=\"left\"))\n",
    "        i0 = max(0, min(i0, int(eta_idx[-1])))\n",
    "        return i0, Wj, floor\n",
    "\n",
    "    running_streak = 0\n",
    "    chosen_index = None\n",
    "    chosen_time = None\n",
    "\n",
    "    for k, (tc, j) in enumerate(zip(user_times, mapped_idx)):\n",
    "        if j < 0:\n",
    "            running_streak = 0\n",
    "            continue\n",
    "\n",
    "        tj = t[j]\n",
    "        i0, Wj, floor = _window_start_index(tj)\n",
    "        W_used_ps[k] = Wj\n",
    "        floor_used[k] = floor\n",
    "\n",
    "        if j - i0 + 1 < 3:\n",
    "            npts_win[k] = j - i0 + 1\n",
    "            running_streak = 0\n",
    "            continue\n",
    "\n",
    "        etaw = eta[i0 : j + 1]\n",
    "        npts_win[k] = etaw.size\n",
    "\n",
    "        emax = float(np.nanmax(etaw))\n",
    "        emin = float(np.nanmin(etaw))\n",
    "        emed = float(np.nanmedian(etaw))\n",
    "        d_abs = emax - emin\n",
    "        d_rel = d_abs / max(abs(emed), 1e-12)\n",
    "\n",
    "        eta_med[k] = emed\n",
    "        eta_mad[k] = _mad(etaw)\n",
    "        abs_range[k] = d_abs\n",
    "        rel_range[k] = d_rel\n",
    "\n",
    "        ok_rel = d_rel <= eps_rel\n",
    "        ok_abs = (d_abs <= eps_abs) if use_abs_check else True\n",
    "\n",
    "        passed = bool(ok_rel and ok_abs)\n",
    "        pass_flags[k] = passed\n",
    "\n",
    "        running_streak = running_streak + 1 if passed else 0\n",
    "        if chosen_index is None and running_streak >= int(pass_streak):\n",
    "            chosen_index = int(j)\n",
    "            chosen_time = float(tc)\n",
    "\n",
    "    ### Write Table\n",
    "    W_cut, W_w, W_n, W_med, W_mad, W_rel, W_abs, W_pass, W_strk = (\n",
    "        10,\n",
    "        10,\n",
    "        9,\n",
    "        10,\n",
    "        9,\n",
    "        9,\n",
    "        9,\n",
    "        4,\n",
    "        6,\n",
    "    )\n",
    "\n",
    "    def H(txt, w):\n",
    "        return f\"{txt:>{w}}\"\n",
    "\n",
    "    width = 84\n",
    "    sep = \"-\" * width\n",
    "    title_line = \"Plateau Window Evaluation\"\n",
    "\n",
    "    hdr = \" \".join(\n",
    "        [\n",
    "            H(\"cutoff(ps)\", W_cut),\n",
    "            H(\"Window(ps)\", W_w),\n",
    "            H(\"#pts\", W_n),\n",
    "            H(\"eta_med\", W_med),\n",
    "            H(\"MAD\", W_mad),\n",
    "            H(\"eps_rel\", W_rel),\n",
    "            H(\"eps_abs\", W_abs),\n",
    "            H(\"pass\", W_pass),\n",
    "            H(\"streak\", W_strk),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    streak_now = 0\n",
    "    for k in range(len(user_times)):\n",
    "        tc, j = user_times[k], mapped_idx[k]\n",
    "        Wj, npt = W_used_ps[k], npts_win[k]\n",
    "        emed, mad = eta_med[k], eta_mad[k]\n",
    "        dr, da = rel_range[k], abs_range[k]\n",
    "        p = pass_flags[k]\n",
    "\n",
    "        if j < 0 or not np.isfinite(Wj):\n",
    "            # Unmapped / invalid candidate: keep alignment with dashes\n",
    "            pass_char = \"N\" if j >= 0 else \"-\"\n",
    "            # keep streak logic only for mapped entries\n",
    "            if j >= 0:\n",
    "                streak_now = streak_now + 1 if p else 0\n",
    "                streak_str = f\"{streak_now}/{pass_streak}\"\n",
    "            else:\n",
    "                streak_str = \"-\"\n",
    "            row = \" \".join(\n",
    "                [\n",
    "                    f\"{tc:{W_cut}.0f}\",\n",
    "                    f\"{'-':>{W_w}}\",\n",
    "                    f\"{'-':>{W_n}}\",\n",
    "                    f\"{'-':>{W_med}}\",\n",
    "                    f\"{'-':>{W_mad}}\",\n",
    "                    f\"{'-':>{W_rel}}\",\n",
    "                    f\"{'-':>{W_abs}}\",\n",
    "                    f\"{pass_char:>{W_pass}}\",\n",
    "                    f\"{streak_str:>{W_strk}}\",\n",
    "                ]\n",
    "            )\n",
    "            rows.append(row)\n",
    "            continue\n",
    "\n",
    "        # mapped candidate\n",
    "        streak_now = streak_now + 1 if p else 0\n",
    "        streak_str = f\"{streak_now}/{pass_streak}\"\n",
    "\n",
    "        row = \" \".join(\n",
    "            [\n",
    "                f\"{tc:{W_cut}.0f}\",\n",
    "                f\"{Wj:{W_w}.1f}\",\n",
    "                f\"{npt:{W_n}d}\",\n",
    "                f\"{emed:{W_med}.4f}\",\n",
    "                f\"{mad:{W_mad}.4f}\",\n",
    "                f\"{dr:{W_rel}.4f}\",\n",
    "                f\"{da:{W_abs}.4f}\",\n",
    "                f\"{('Y' if p else 'N'):>{W_pass}}\",\n",
    "                f\"{streak_str:>{W_strk}}\",\n",
    "            ]\n",
    "        )\n",
    "        rows.append(row)\n",
    "\n",
    "    table_lines = [sep, title_line, sep, hdr, sep, *rows, sep]\n",
    "\n",
    "    table = \"\\n\".join(table_lines)\n",
    "\n",
    "    if log:\n",
    "        for line in table.splitlines():\n",
    "            log.add(line)\n",
    "        if np.any(floor_used):\n",
    "            log.add(\"NOTE:\")\n",
    "            log.add(\n",
    "                \"The trailing window was clamped to the internal minimum (0.5 ps) for one or\"\n",
    "            )\n",
    "            log.add(\n",
    "                \"more candidates. This typically happens for early cutoffs where the fractional\"\n",
    "            )\n",
    "            log.add(\n",
    "                \"window would be smaller than 0.5 ps. Consider increasing W_fraction or starting\"\n",
    "            )\n",
    "            log.add(\"candidates later if this is not desired.\")\n",
    "        log.write()\n",
    "\n",
    "    return CutoffResult(\n",
    "        chosen_index=chosen_index,\n",
    "        chosen_time_ps=chosen_time,\n",
    "        pass_streak=pass_streak,\n",
    "        params={\n",
    "            \"W_fraction\": W_fraction,\n",
    "            \"eps_rel\": eps_rel,\n",
    "            \"eps_abs\": eps_abs,\n",
    "            \"pass_streak\": pass_streak,\n",
    "        },\n",
    "        candidate_times_ps=user_times,\n",
    "        mapped_indices=mapped_idx,\n",
    "        pass_flags=pass_flags,\n",
    "        rel_range=rel_range,\n",
    "        abs_range=abs_range,\n",
    "        window_sizes_ps=W_used_ps,\n",
    "        window_counts=npts_win,\n",
    "        eta_median=eta_med,\n",
    "        eta_mad=eta_mad,\n",
    "        table=table,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00957364",
   "metadata": {},
   "source": [
    "### Required Arguments\n",
    "\n",
    "`parquet_path` Path to input Parquet with columns time_ps, mean, stdev.\n",
    "\n",
    "`candidate_times_ps` List of candidate cutoff times in picoseconds\n",
    "\n",
    "### Optional Arguments\n",
    "\n",
    "`W_fraction` Fraction of datapoints to include in the trailing window.\n",
    "\n",
    "`eps_rel` Relative tolerance for plateau acceptance (default: 0.05).\n",
    "\n",
    "`eps_abs` Absolute tolerance (optional). If omitted, absolute check is disabled.\n",
    "\n",
    "`streak` Minimum streak required for a pass result (default: 2)\n",
    "\n",
    "`log_name` Output log file (default: \"plateau_check.log\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "parquet_path = \"\" \n",
    "candidate_times_ps = []\n",
    "\n",
    "results = cutoff_checker(\n",
    "    parquet_path,\n",
    "    *,\n",
    "    candidate_times_ps,\n",
    "    W_fraction=0.10,\n",
    "    eps_rel=0.02,\n",
    "    eps_abs=None,\n",
    "    pass_streak=2,\n",
    "    log_name=\"plateau_check.log\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
