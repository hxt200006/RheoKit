{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from math import ceil, floor\n",
    "import traceback\n",
    "import json\n",
    "import sys\n",
    "import argparse\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Objects\n",
    "# Helper, ensures parquet data is immuatable\n",
    "def _ro_f64(a):\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    a.setflags(write=False)\n",
    "    return a\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class IngestData:\n",
    "    \"\"\"Arrays extracted from Parquet.\"\"\"\n",
    "\n",
    "    time_ps: np.ndarray\n",
    "    mean: np.ndarray\n",
    "    stdev: np.ndarray\n",
    "    n_rows: int\n",
    "\n",
    "    @classmethod\n",
    "    def make(cls, time_ps, mean, stdev):\n",
    "        \"\"\" \"Normalize data types\"\"\"\n",
    "        tp = _ro_f64(time_ps)\n",
    "        m = _ro_f64(mean)\n",
    "        sd = _ro_f64(stdev)\n",
    "        if not (len(tp) == len(m) == len(sd)):\n",
    "            raise ValueError(\"Column lengths differ.\")\n",
    "        return cls(tp, m, sd, len(tp))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MaskInfo:\n",
    "    \"\"\"Masks and index windows for eta and sigma fits.\"\"\"\n",
    "\n",
    "    tmin_ps: float\n",
    "    tmax_ps: float\n",
    "    i0_eta: int\n",
    "    i1_eta: int\n",
    "    i1_sigma: int\n",
    "    eta_mask: np.ndarray\n",
    "    sigma_mask: np.ndarray\n",
    "    n_eta: int\n",
    "    n_sigma: int\n",
    "\n",
    "\n",
    "class FitResult:\n",
    "    \"\"\"\n",
    "    Container for fitted parameters with built-in JSON I/O.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        File path for saving/loading parameter JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path=None, sigma_params=None, eta_params=None):\n",
    "        default = \"ViscoFit.json\"\n",
    "        base = Path(path or default)\n",
    "        base.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.path = self._resolve_unique_path(base)\n",
    "        self.sigma_params = sigma_params or {}\n",
    "        self.eta_params = eta_params or {}\n",
    "\n",
    "    def _resolve_unique_path(self, base):\n",
    "        stem, suffix = base.stem, base.suffix or \"\"\n",
    "        i = 0\n",
    "        while True:\n",
    "            candidate = base if i == 0 else base.with_name(f\"{stem}_{i + 1}{suffix}\")\n",
    "            try:\n",
    "                # Atomic create for safety\n",
    "                with open(candidate, \"x\", encoding=\"utf-8\") as fh:\n",
    "                    fh.write(\"\")\n",
    "                return candidate\n",
    "            except FileExistsError:\n",
    "                i += 1\n",
    "\n",
    "    def write(self):\n",
    "        \"\"\"Write parameters to self.path as JSON.\"\"\"\n",
    "        data = {\n",
    "            \"sigma_params\": self.sigma_params,\n",
    "            \"eta_params\": self.eta_params,\n",
    "        }\n",
    "        with open(self.path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FitResult(path='{self.path}', sigma={self.sigma_params}, eta={self.eta_params})\"\n",
    "\n",
    "\n",
    "class RunLog:\n",
    "    \"\"\"Line-oriented logger.\"\"\"\n",
    "\n",
    "    def __init__(self, log_name=None, program=None):\n",
    "        default = \"ViscoFit.log\"\n",
    "        base = Path(log_name or default)\n",
    "        base.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.path = self._resolve_unique_path(base)\n",
    "        self.program = program or \"generic\"\n",
    "        self._lines = []\n",
    "        self._write_header()\n",
    "\n",
    "    def _resolve_unique_path(self, base):\n",
    "        stem, suffix = base.stem, base.suffix or \"\"\n",
    "        i = 0\n",
    "        while True:\n",
    "            candidate = base if i == 0 else base.with_name(f\"{stem}_{i + 1}{suffix}\")\n",
    "            try:\n",
    "                # Atomic create for safety\n",
    "                with open(candidate, \"x\", encoding=\"utf-8\") as fh:\n",
    "                    fh.write(\"\")\n",
    "                return candidate\n",
    "            except FileExistsError:\n",
    "                i += 1\n",
    "\n",
    "    def _stamp(self):\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    def _write_header(self):\n",
    "        \"\"\"Write header block at instantiation.\"\"\"\n",
    "        if self.program == \"generic\":\n",
    "            program_name = \"RheoKit\"\n",
    "        elif self.program == \"platchk\":\n",
    "            program_name = \"RheoKit: Plateau Check\"\n",
    "        elif self.program == \"cvfit\":\n",
    "            program_name = \"RheoKit: Stress Fit\"\n",
    "        elif self.program == \"runGK\":\n",
    "            program_name = \"RheoKit: GK Integrate\"\n",
    "\n",
    "        author_name = \"Daniel Relix\"\n",
    "        timestamp = self._stamp()\n",
    "\n",
    "        box_width = 64\n",
    "        left_margin = \" \" * 13\n",
    "        pad_inside = box_width - 4  # subtract 2 chars for each '##'\n",
    "        line = lambda text=\"\": f\"{left_margin}##  {text:<{pad_inside - 2}}##\"\n",
    "\n",
    "        header = [\n",
    "            \"\",\n",
    "            left_margin + \"#\" * box_width,\n",
    "            left_margin + \"##\" + \" \" * (box_width - 4) + \"##\",\n",
    "            line(program_name),\n",
    "            line(f\"By {author_name}\"),\n",
    "            left_margin + \"##\" + \" \" * (box_width - 4) + \"##\",\n",
    "            left_margin + \"#\" * box_width,\n",
    "            \"\",\n",
    "            f\"Job started: {timestamp}\",\n",
    "            f\"Log file: {self.path.name}\",\n",
    "            \"\",\n",
    "        ]\n",
    "\n",
    "        self._lines.extend(header)\n",
    "        self.write()\n",
    "\n",
    "    def add(self, line=\"\"):\n",
    "        self._lines.append(\"   \" + line)\n",
    "\n",
    "    def section(self, title):\n",
    "        self._lines.append(\"-\" * 90)\n",
    "        self._lines.append(title)\n",
    "\n",
    "    def subsection(self, title):\n",
    "        self._lines.append(title)\n",
    "\n",
    "    def write(self):\n",
    "        self.path.write_text(\"\\n\".join(self._lines) + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "    def exception(self, logtext, e):\n",
    "        self._lines.append(f\"Exception: {logtext}\")\n",
    "        tb = \"\".join(traceback.format_exception(type(e), e, e.__traceback__))\n",
    "        self._lines.append(tb.rstrip(\"\\n\"))\n",
    "        self.write()\n",
    "\n",
    "\n",
    "### Models and helper functions\n",
    "\n",
    "\n",
    "def eta_fit(t, A_eta, alpha, tau1, tau2):\n",
    "    \"\"\"\n",
    "    Double exponential fit for the Greenâ€“Kubo integral.\n",
    "    eta(0)=0 and eta(t->inf)=A_eta.\n",
    "    \"\"\"\n",
    "    return A_eta * alpha * tau1 * (1.0 - np.exp(-t / tau1)) + A_eta * (\n",
    "        1.0 - alpha\n",
    "    ) * tau2 * (1.0 - np.exp(-t / tau2))\n",
    "\n",
    "\n",
    "def sigma_fit(x, A_sigma, b):\n",
    "    \"\"\"Power function fit to get weighing parameter.\"\"\"\n",
    "    return A_sigma * (x**b)\n",
    "\n",
    "\n",
    "def _clamp(x, lo, hi):\n",
    "    \"\"\"Clamp x between lo and hi.\"\"\"\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "\n",
    "def _auto_fmt(arr, decimals=12):\n",
    "    \"\"\"Return a NumPy array2string formatter that aligns floats by decimal.\"\"\"\n",
    "\n",
    "    max_val = np.max(np.abs(arr))\n",
    "    int_width = len(str(int(max_val))) + 1\n",
    "    total_width = int_width + decimals + 1\n",
    "    fmt = f\"{{:{total_width}.{decimals}f}}\"\n",
    "    return {\"float_kind\": lambda x, f=fmt: f.format(x)}\n",
    "\n",
    "\n",
    "def _init_eta_params(data, mask, log=None):\n",
    "    \"\"\"\n",
    "    Build initial guess [A_eta0, alpha0, tau1_0, tau2_0] from the\n",
    "    estimated plateau at the tail of the eta window.\n",
    "    \"\"\"\n",
    "\n",
    "    # alpha is a mixing coefficient.\n",
    "    alpha0 = 0.5\n",
    "\n",
    "    # tau guesses are based on length of simulation.\n",
    "    t_masked = data.time_ps[mask.eta_mask]\n",
    "    n = len(t_masked)\n",
    "    if n > 1:\n",
    "        dt_med = float(np.median(np.diff(t_masked)))\n",
    "        span = float(t_masked[-1] - t_masked[0])\n",
    "    else:\n",
    "        dt_med, span = 1.0, 1.0\n",
    "    if span <= 0:\n",
    "        span = max(dt_med, 1.0)\n",
    "\n",
    "    tau1_0 = _clamp(0.01 * span, 2.0 * dt_med, 0.10 * span)\n",
    "    tau2_0 = _clamp(0.35 * span, 5.0 * dt_med, 1.00 * span)\n",
    "    if tau1_0 > tau2_0:\n",
    "        tau1_0, tau2_0 = tau2_0, tau1_0\n",
    "\n",
    "    # A_eta guess based on median of eta(t) tail.\n",
    "    # (Scaled from symbolic limit)\n",
    "    # First, get the median of the last 5% of the tail.\n",
    "    K = int(round(0.05 * n))\n",
    "    K = max(500, K)\n",
    "    K = min(K, 1000000)\n",
    "\n",
    "    # Use a stride if there's a lot of sampling\n",
    "    if K >= 100000:\n",
    "        s = -(-K // 100000)\n",
    "        eta_inf0 = float(np.median(data.mean[-K::s]))\n",
    "    else:\n",
    "        eta_inf0 = float(np.median(data.mean[-K:]))\n",
    "\n",
    "    # Then, calculate symbolic limit\n",
    "    denom = alpha0 * tau1_0 + (1.0 - alpha0) * tau2_0\n",
    "    if denom <= 0 or not np.isfinite(denom):\n",
    "        A_eta0 = max(0.0, (data.mean[-1] - data.mean[0]) / max(span, dt_med))\n",
    "    else:\n",
    "        A_eta0 = max(0.0, eta_inf0 / denom)\n",
    "\n",
    "    return np.array([A_eta0, alpha0, tau1_0, tau2_0], dtype=float)\n",
    "\n",
    "\n",
    "### Main Logic:\n",
    "### 1. Read in Data\n",
    "### 2. Make Masks\n",
    "### 3. run curve_fit()\n",
    "\n",
    "\n",
    "def load_parquet(path, log=None):\n",
    "    \"\"\"\n",
    "    Load Parquet with required columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the Parquet file.\n",
    "    log : RunLog or None\n",
    "        Optional logger to record a brief ingest block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    IngestData\n",
    "        time_ps, mean, stdev as float64 arrays and row count.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If required columns are missing.\n",
    "    \"\"\"\n",
    "\n",
    "    required_cols = (\"Time (ps)\", \"Mean\", \"StDev\")\n",
    "    df = pd.read_parquet(path, columns=[\"Time (ps)\", \"Mean\", \"StDev\"])\n",
    "    data = IngestData.make(df[\"Time (ps)\"], df[\"Mean\"], df[\"StDev\"])\n",
    "\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    if log is not None:\n",
    "        log.section(\"INPUT DATA\")\n",
    "        log.add()\n",
    "\n",
    "        log.add(f\"File               : {path}\")\n",
    "        log.add(f\"Total Data Points  : {data.n_rows}\")\n",
    "        log.add()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_masks(time_ps, tmin_ps=2.0, tmax_ps=None, log=None, *, silent=False):\n",
    "    \"\"\"\n",
    "    Build eta and sigma windows/masks using times in ps.\n",
    "\n",
    "    Windows:\n",
    "      - eta   : [tmin_ps, tmax_ps]  (default tmin_ps=2.0)\n",
    "      - sigma : [0,       tmax_ps]  (shares the same cutoff)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_ps : np.ndarray\n",
    "        1D array of times (ps), length N.\n",
    "    tmin_ps : float\n",
    "        Start time (ps) for eta window. Default is 2.0 ps.\n",
    "    tmax_ps : float or None\n",
    "        End time (ps). If None, uses the last time in the array.\n",
    "    log : RunLog or None\n",
    "        Optional logger to record window details.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MaskInfo\n",
    "        Indices, masks, and counts for eta and sigma windows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Precompute grid facts\n",
    "    n = len(time_ps)\n",
    "    t_lo = float(time_ps[0])\n",
    "    t_hi = float(time_ps[-1])\n",
    "    dt_ps = float(time_ps[1] - time_ps[0]) if n > 1 else 0.0\n",
    "    tmax_user = t_hi if tmax_ps is None else float(tmax_ps)\n",
    "\n",
    "    # Clamp requested window\n",
    "    tmin_c = _clamp(float(tmin_ps), t_lo, t_hi)\n",
    "    tmax_c = _clamp(float(tmax_user), tmin_c, t_hi)\n",
    "\n",
    "    # Map times to inclusive index range on a uniform grid\n",
    "    i0_eta = int(ceil((tmin_c - t_lo) / dt_ps))\n",
    "    i1_eta = int(floor((tmax_c - t_lo) / dt_ps))\n",
    "\n",
    "    # Clamp mapped idx on [0, n-1] for safety\n",
    "    i0_eta = _clamp(i0_eta, 0, n - 1)\n",
    "    i1_eta = _clamp(i1_eta, i0_eta, n - 1)\n",
    "\n",
    "    # Sigma starts at 0 and ends at same cutoff as eta\n",
    "    i1_sigma = i1_eta\n",
    "\n",
    "    # Make the masks\n",
    "    N = time_ps.size\n",
    "    eta_mask = np.zeros(N, dtype=bool)\n",
    "    sigma_mask = np.zeros(N, dtype=bool)\n",
    "    eta_mask[i0_eta : i1_eta + 1] = True\n",
    "    sigma_mask[0 : i1_sigma + 1] = True\n",
    "\n",
    "    n_eta = int(eta_mask.sum())\n",
    "    n_sigma = int(sigma_mask.sum())\n",
    "\n",
    "    if not silent and log is not None:\n",
    "        log.section(\"MASK INFORMATION\")\n",
    "        log.add()\n",
    "        log.add(f\"Sigma Fit Range    : {0.0:.6g} - {tmax_c:.6g} ps \")\n",
    "        log.add(f\"Index Range        : [0, {i1_sigma}]\")\n",
    "        log.add()\n",
    "\n",
    "        if tmax_ps is not None and tmax_ps > t_hi:\n",
    "            log.add(f\"Requested end time ({tmax_ps:.3f} ps)\")\n",
    "            log.add(f\"exceeds available data ({t_hi:.3f} ps).\")\n",
    "            log.add(f\"Using {tmax_c:.3f} ps instead.\")\n",
    "            log.add()\n",
    "\n",
    "        log.add(f\"Eta Fit Range      : {tmin_c:.6g} - {tmax_c:.6g} ps\")\n",
    "        log.add(f\"Index Range        : [{i0_eta}, {i1_eta}]\")\n",
    "        log.add(f\"Points in Eta Fit  : {n_eta}\")\n",
    "        log.add()\n",
    "\n",
    "    masks = MaskInfo(\n",
    "        tmin_ps=tmin_c,\n",
    "        tmax_ps=tmax_c,\n",
    "        i0_eta=i0_eta,\n",
    "        i1_eta=i1_eta,\n",
    "        i1_sigma=i1_sigma,\n",
    "        eta_mask=eta_mask,\n",
    "        sigma_mask=sigma_mask,\n",
    "        n_eta=n_eta,\n",
    "        n_sigma=n_sigma,\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def run_curve_fit(data, mask, weight_mode=\"soft\", json_name=None, log=None):\n",
    "    # Sigma: Power-law fit\n",
    "    t_sigma = data.time_ps[mask.sigma_mask]\n",
    "    y_sigma = data.stdev[mask.sigma_mask]\n",
    "\n",
    "    popt_sigma, pcov_sigma = curve_fit(sigma_fit, t_sigma, y_sigma, maxfev=1000)\n",
    "\n",
    "    # Collect ending sigma value for ~40% comparison\n",
    "    std_fit_cf = sigma_fit(t_sigma, *popt_sigma)\n",
    "    sigma_val_cf = float(std_fit_cf[-100])\n",
    "\n",
    "    # Eta: Double exponential fit\n",
    "    y_eta = data.mean[mask.eta_mask]\n",
    "    t_eta = data.time_ps[mask.eta_mask]\n",
    "    dt_med = float(np.median(np.diff(t_eta)))\n",
    "    tmax = t_eta[-1]\n",
    "\n",
    "    # Initial guesses for eta params and their bounds\n",
    "    p0 = _init_eta_params(data, mask=mask, log=log)\n",
    "    A_eta0, alpha0, tau1_0, tau2_0 = map(float, p0)\n",
    "    bounds = (\n",
    "        [-np.inf, 0.000001, (dt_med * 0.5), (dt_med * 100)],\n",
    "        [np.inf, 0.999999, (tmax * 0.15), (tmax * 0.5)],\n",
    "    )\n",
    "\n",
    "    # Build eta weights with b_cf\n",
    "    A_sigma_cf, b_cf = map(float, popt_sigma)\n",
    "    if weight_mode == \"soft\":\n",
    "        weights = t_eta ** (b_cf / 2.0)  # weight ~ x^{-b}\n",
    "    elif weight_mode == \"heavy\":\n",
    "        weights = t_eta ** (b_cf)  # weight ~ x^{-2b}\n",
    "    else:\n",
    "        raise ValueError(\"weight_mode must be 'soft' or 'heavy'\")\n",
    "\n",
    "    try:\n",
    "        popt_eta, pcov_eta = curve_fit(\n",
    "            eta_fit,\n",
    "            t_eta,\n",
    "            y_eta,\n",
    "            p0=p0,\n",
    "            bounds=bounds,\n",
    "            sigma=weights,\n",
    "            absolute_sigma=True,\n",
    "            maxfev=10000,\n",
    "        )\n",
    "        reordered = False\n",
    "        A_eta, alpha, tau1, tau2 = map(float, popt_eta)\n",
    "        if tau1 > tau2:\n",
    "            tau1, tau2 = tau2, tau1\n",
    "            alpha = 1.0 - alpha\n",
    "            popt_eta = np.array([A_eta, alpha, tau1, tau2])\n",
    "            idx = [0, 1, 3, 2]\n",
    "            pcov_eta = pcov_eta[np.ix_(idx, idx)]\n",
    "            reordered = True\n",
    "        rse_eta = np.sqrt(np.diag(pcov_eta)) / np.abs(popt_eta) * 100\n",
    "        A_eta_rse, alpha_rse, tau1_rse, tau2_rse = map(float, rse_eta)\n",
    "        eta_inf = A_eta * (alpha * tau1 + (1 - alpha) * tau2)\n",
    "        eta_fit_cf = eta_fit(t_eta, *popt_eta)\n",
    "        eta_val_cf = float(eta_fit_cf[-100])\n",
    "\n",
    "    except Exception as e:\n",
    "        if log is not None:\n",
    "            log.exception(\"curve_fit() failed with error:\", e)\n",
    "            raise Exception\n",
    "\n",
    "    if log is not None:\n",
    "        log.section(\"FIT SUMMARY\")\n",
    "        log.add()\n",
    "\n",
    "        log.subsection(\"Eta parameter initial guesses:\")\n",
    "        log.add(f\"A_eta              : {A_eta0:0.8f}\")\n",
    "        log.add(f\"alpha              : {alpha0}\")\n",
    "        log.add(f\"tau1               : {tau1_0:0.4f}\")\n",
    "        log.add(f\"tau2               : {tau2_0:0.4f}\")\n",
    "        log.add()\n",
    "\n",
    "        log.subsection(\"Sigma fit results:\")\n",
    "        log.add(f\"A_sigma            : {A_sigma_cf:.6f}\")\n",
    "        log.add(f\"b                  : {b_cf:.6f}\")\n",
    "        log.add(f\"St. Dev. at cutoff : {sigma_val_cf:.6f}\")\n",
    "        log.add(\n",
    "            f\"Covariance Matrix  : {np.array2string(pcov_sigma, formatter=_auto_fmt(pcov_sigma)).replace('\\n', '\\n' + ' ' * 23)}\"\n",
    "        )\n",
    "        log.add()\n",
    "\n",
    "        log.subsection(\"Eta fit results:\")\n",
    "        log.add(f\"A_eta              : {A_eta:.6f}\")\n",
    "        log.add(f\"alpha              : {alpha}\")\n",
    "        log.add(f\"tau1               : {tau1:.6f} (RSE = {tau1_rse:12.2f}%)\")\n",
    "        log.add(f\"tau2               : {tau2:.6f} (RSE = {tau2_rse:12.2f}%)\")\n",
    "        if weight_mode == \"heavy\":\n",
    "            log.add(\"weight mode        : heavy\")\n",
    "        log.add(f\"Viscosity at cutoff: {eta_val_cf:.6f}\")\n",
    "        log.add(f\"sigma(t_cut)/eta(t_cut): {(sigma_val_cf / eta_val_cf):6g}\")\n",
    "        log.add(\"Covariance Matrix  :\")\n",
    "        log.add(\n",
    "            f\"{np.array2string(pcov_eta, formatter=_auto_fmt(pcov_eta), max_line_width=np.inf, threshold=np.inf).replace('\\n', '\\n' + ' ' * 3)}\"\n",
    "        )\n",
    "        if reordered:\n",
    "            log.add()\n",
    "            log.subsection(\n",
    "                \"NOTE: tau1 and tau2 switched during fit. Parameters and covariance reordered.\"\n",
    "            )\n",
    "\n",
    "        log.add()\n",
    "\n",
    "        log.section(\"RESULTS\")\n",
    "        log.add()\n",
    "        log.add(f\"Final Viscosity    : {eta_inf}\")\n",
    "\n",
    "    cf_results = FitResult(\n",
    "        path=json_name,\n",
    "        sigma_params={\"A_sigma\": A_sigma_cf, \"b\": b_cf},\n",
    "        eta_params={\"A_eta\": A_eta, \"alpha\": alpha, \"tau1\": tau1, \"tau2\": tau2},\n",
    "    )\n",
    "    return cf_results\n",
    "\n",
    "\n",
    "### Wrapper for main logic\n",
    "def fit_procedure(\n",
    "    log_name, json_name, parquet_path, tmin_ps=2.0, tmax_ps=None, weight_mode=\"soft\"\n",
    "):\n",
    "    log = RunLog(log_name=log_name, program=\"cvfit\")\n",
    "    data = load_parquet(parquet_path, log=log)\n",
    "    masks = build_masks(data.time_ps, tmin_ps=tmin_ps, tmax_ps=tmax_ps, log=log)\n",
    "    results = run_curve_fit(\n",
    "        data, mask=masks, json_name=json_name, weight_mode=weight_mode, log=log\n",
    "    )\n",
    "    log.write()\n",
    "    results.write()\n",
    "    return results, log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4a8e6",
   "metadata": {},
   "source": [
    "### Required Arguments \n",
    "\n",
    "`parquet_path` Path to the input parquet file.\n",
    "\n",
    "`tmax_ps` cutoff time to use in curve fitting procedure.\n",
    "\n",
    "`tmin_ps` start time to include in curve fitting procedure. Default: 2.0 ps\n",
    "\n",
    "### Optional Arguments\n",
    "\n",
    "`log_name` Output log filename. Default: \"Stress_Fit.log\"\n",
    "\n",
    "`json_name` Output json filename. Stores parameters from both standard deviation and GK integral fitting.\n",
    "\n",
    "`weight_mode` Weighting mode to prioritize eariler timscales. Can be 'soft' or 'heavy'. Default: soft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "# Required Arguments\n",
    "parquet_path = \"\"\n",
    "tmax_ps = None\n",
    "\n",
    "\n",
    "results, log = fit_procedure(log_name=\"Stress_Fit.log\", json_name=\"Stress_Fit.json\", parquet_path, tmin_ps=2.0, tmax_ps=None, weight_mode=\"soft\") "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
